{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import expanduser, join\n",
    "import pathlib\n",
    "\n",
    "root = pathlib.Path().resolve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "\n",
    "dir = listdir(root)\n",
    "if 't.ex-Graph' in dir:\n",
    "  root = join(root, 't.ex-Graph')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, join(root, 'lib'))\n",
    "\n",
    "import config\n",
    "import functions\n",
    "import data\n",
    "import model\n",
    "import export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = [{\n",
    "    'label': 'HTTP/S Graph (SLDs)',\n",
    "    'data': data.read(join(root, 'data', 'graph-data-sld.csv'))\n",
    "  }, {\n",
    "    'label': 'HTTP/S Graph (FQDN)',\n",
    "    'data': data.read(join(root, 'data', 'graph-data-fqdn.csv'))\n",
    "  }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [col for col in list(datasets[0].get('data').columns) if col.lower() not in ['id', 'weight', 'tracker']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "for dataset in datasets:\n",
    "  dataset.get('data')['tracker'] = LabelEncoder().fit_transform(dataset.get('data')['tracker'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "extension = []\n",
    "for dataset in datasets:\n",
    "  extension.append({\n",
    "    'label': dataset.get('label') + ' 50/50',\n",
    "    'data': data.sample_equal_distribution(dataset.get('data'), 'tracker')\n",
    "  })\n",
    "\n",
    "datasets.extend(extension)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "models = {\n",
    "  'continuous': [\n",
    "    LinearRegression(n_jobs=-1),\n",
    "    RandomForestRegressor(n_estimators=200, random_state=0, n_jobs=-1)\n",
    "  ],\n",
    "  'category':[\n",
    "    DecisionTreeClassifier(),\n",
    "    LogisticRegression(solver='lbfgs', max_iter=1000, n_jobs=-1)\n",
    "  ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [9], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39mrun_line_magic(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmatplotlib\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124magg\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_results\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m  \u001b[49m\u001b[43mdatasets\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m  \u001b[49m\u001b[43mmodels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m  \u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m  \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mweight\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtracker\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Arbeit/PhD/Data/Graph/lib/model.py:50\u001b[0m, in \u001b[0;36mcompute_results\u001b[0;34m(datasets, models, features, targets)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[39mif\u001b[39;00m dataset\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39mlabel\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m results:\n\u001b[1;32m     48\u001b[0m       results[dataset\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39mlabel\u001b[39m\u001b[39m'\u001b[39m)] \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m()\n\u001b[0;32m---> 50\u001b[0m     results[dataset\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39mlabel\u001b[39m\u001b[39m'\u001b[39m)] \u001b[39m=\u001b[39m { \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mresults[dataset\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39mlabel\u001b[39m\u001b[39m'\u001b[39m)], \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mtest_models_on_dataset(models, dataset\u001b[39m.\u001b[39;49mget(\u001b[39m'\u001b[39;49m\u001b[39mdata\u001b[39;49m\u001b[39m'\u001b[39;49m), features, target) }\n\u001b[1;32m     52\u001b[0m \u001b[39mreturn\u001b[39;00m results\n",
      "File \u001b[0;32m~/Arbeit/PhD/Data/Graph/lib/model.py:38\u001b[0m, in \u001b[0;36mtest_models_on_dataset\u001b[0;34m(models, dataset, features, target)\u001b[0m\n\u001b[1;32m     35\u001b[0m output \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m()\n\u001b[1;32m     37\u001b[0m \u001b[39mfor\u001b[39;00m model \u001b[39min\u001b[39;00m m:\n\u001b[0;32m---> 38\u001b[0m   output \u001b[39m=\u001b[39m { \u001b[39m*\u001b[39m\u001b[39m*\u001b[39moutput, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mtest(model, continuous, X, y, X_train, X_test, y_train, y_test, features) }\n\u001b[1;32m     40\u001b[0m \u001b[39mreturn\u001b[39;00m output\n",
      "File \u001b[0;32m~/Arbeit/PhD/Data/Graph/lib/model.py:19\u001b[0m, in \u001b[0;36mtest\u001b[0;34m(model, continuous, X, y, X_train, X_test, y_train, y_test, features)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     17\u001b[0m   result[\u001b[39m'\u001b[39m\u001b[39mtrain_test\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m report\u001b[39m.\u001b[39mcategory(y_test, predictions)\n\u001b[0;32m---> 19\u001b[0m result[\u001b[39m'\u001b[39m\u001b[39mfeature_importance\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m report\u001b[39m.\u001b[39;49mfeature_importance(model, X_test, y_test, features)\n\u001b[1;32m     20\u001b[0m result[\u001b[39m'\u001b[39m\u001b[39mcross_validation\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m report\u001b[39m.\u001b[39mcross_validation(model, X, y)\n\u001b[1;32m     22\u001b[0m output \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m()\n",
      "File \u001b[0;32m~/Arbeit/PhD/Data/Graph/lib/report.py:26\u001b[0m, in \u001b[0;36mfeature_importance\u001b[0;34m(model, X_test, y_test, features)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfeature_importance\u001b[39m(model, X_test, y_test, features):\n\u001b[0;32m---> 26\u001b[0m   result \u001b[39m=\u001b[39m permutation_importance(\n\u001b[1;32m     27\u001b[0m     model, X_test, y_test, n_repeats\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m, random_state\u001b[39m=\u001b[39;49m\u001b[39m42\u001b[39;49m, n_jobs\u001b[39m=\u001b[39;49m\u001b[39m2\u001b[39;49m\n\u001b[1;32m     28\u001b[0m   )\n\u001b[1;32m     29\u001b[0m   importances \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mSeries(result\u001b[39m.\u001b[39mimportances_mean, index\u001b[39m=\u001b[39mfeatures)\n\u001b[1;32m     31\u001b[0m   \u001b[39mreturn\u001b[39;00m {\n\u001b[1;32m     32\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mresult\u001b[39m\u001b[39m'\u001b[39m: result,\n\u001b[1;32m     33\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mimportances\u001b[39m\u001b[39m'\u001b[39m: importances\n\u001b[1;32m     34\u001b[0m   }\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/inspection/_permutation_importance.py:259\u001b[0m, in \u001b[0;36mpermutation_importance\u001b[0;34m(estimator, X, y, scoring, n_repeats, n_jobs, random_state, sample_weight, max_samples)\u001b[0m\n\u001b[1;32m    255\u001b[0m     scorer \u001b[39m=\u001b[39m _MultimetricScorer(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mscorers_dict)\n\u001b[1;32m    257\u001b[0m baseline_score \u001b[39m=\u001b[39m _weights_scorer(scorer, estimator, X, y, sample_weight)\n\u001b[0;32m--> 259\u001b[0m scores \u001b[39m=\u001b[39m Parallel(n_jobs\u001b[39m=\u001b[39;49mn_jobs)(\n\u001b[1;32m    260\u001b[0m     delayed(_calculate_permutation_scores)(\n\u001b[1;32m    261\u001b[0m         estimator,\n\u001b[1;32m    262\u001b[0m         X,\n\u001b[1;32m    263\u001b[0m         y,\n\u001b[1;32m    264\u001b[0m         sample_weight,\n\u001b[1;32m    265\u001b[0m         col_idx,\n\u001b[1;32m    266\u001b[0m         random_seed,\n\u001b[1;32m    267\u001b[0m         n_repeats,\n\u001b[1;32m    268\u001b[0m         scorer,\n\u001b[1;32m    269\u001b[0m         max_samples,\n\u001b[1;32m    270\u001b[0m     )\n\u001b[1;32m    271\u001b[0m     \u001b[39mfor\u001b[39;49;00m col_idx \u001b[39min\u001b[39;49;00m \u001b[39mrange\u001b[39;49m(X\u001b[39m.\u001b[39;49mshape[\u001b[39m1\u001b[39;49m])\n\u001b[1;32m    272\u001b[0m )\n\u001b[1;32m    274\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(baseline_score, \u001b[39mdict\u001b[39m):\n\u001b[1;32m    275\u001b[0m     \u001b[39mreturn\u001b[39;00m {\n\u001b[1;32m    276\u001b[0m         name: _create_importances_bunch(\n\u001b[1;32m    277\u001b[0m             baseline_score[name],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    281\u001b[0m         \u001b[39mfor\u001b[39;00m name \u001b[39min\u001b[39;00m baseline_score\n\u001b[1;32m    282\u001b[0m     }\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/joblib/parallel.py:1098\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1095\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m   1097\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend\u001b[39m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1098\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mretrieve()\n\u001b[1;32m   1099\u001b[0m \u001b[39m# Make sure that we get a last message telling us we are done\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m elapsed_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_start_time\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/joblib/parallel.py:975\u001b[0m, in \u001b[0;36mParallel.retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    973\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    974\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, \u001b[39m'\u001b[39m\u001b[39msupports_timeout\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mFalse\u001b[39;00m):\n\u001b[0;32m--> 975\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output\u001b[39m.\u001b[39mextend(job\u001b[39m.\u001b[39;49mget(timeout\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtimeout))\n\u001b[1;32m    976\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    977\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output\u001b[39m.\u001b[39mextend(job\u001b[39m.\u001b[39mget())\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/joblib/_parallel_backends.py:567\u001b[0m, in \u001b[0;36mLokyBackend.wrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    564\u001b[0m \u001b[39m\"\"\"Wrapper for Future.result to implement the same behaviour as\u001b[39;00m\n\u001b[1;32m    565\u001b[0m \u001b[39mAsyncResults.get from multiprocessing.\"\"\"\u001b[39;00m\n\u001b[1;32m    566\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 567\u001b[0m     \u001b[39mreturn\u001b[39;00m future\u001b[39m.\u001b[39;49mresult(timeout\u001b[39m=\u001b[39;49mtimeout)\n\u001b[1;32m    568\u001b[0m \u001b[39mexcept\u001b[39;00m CfTimeoutError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    569\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTimeoutError\u001b[39;00m \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3.10/concurrent/futures/_base.py:453\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    450\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39m==\u001b[39m FINISHED:\n\u001b[1;32m    451\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__get_result()\n\u001b[0;32m--> 453\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_condition\u001b[39m.\u001b[39;49mwait(timeout)\n\u001b[1;32m    455\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n\u001b[1;32m    456\u001b[0m     \u001b[39mraise\u001b[39;00m CancelledError()\n",
      "File \u001b[0;32m/usr/lib/python3.10/threading.py:320\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[39mtry\u001b[39;00m:    \u001b[39m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    319\u001b[0m     \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 320\u001b[0m         waiter\u001b[39m.\u001b[39;49macquire()\n\u001b[1;32m    321\u001b[0m         gotit \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    322\u001b[0m     \u001b[39melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%matplotlib agg\n",
    "\n",
    "results = model.compute_results(\n",
    "  datasets, \n",
    "  models, \n",
    "  features, \n",
    "  ['weight', 'tracker']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "export.classification_results(results, root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "export.aggregated_classification_results(root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ncols = max(len(models['continuous']), len(models['category']))\n",
    "export.feature_importances(2, ncols, results, root)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
