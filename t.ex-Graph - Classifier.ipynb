{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Up\n",
    "\n",
    "1. We set ```%load_ext autoreload``` and ```%autoreload 2``` to reload modules instantly when changes had been made in these modules.\n",
    "2. We use the Intel(R) Extension for Scikit-learn.\n",
    "3. We identify the ```root``` directory with ```pathlib.Path().resolve()```. In case the Jupyter Notebook is connected with a remote Jupyter server, we look for the directory ```t.ex-Graph``` in ```root```. **NOTE:** Therefore, you have to clone the ```t.ex-Graph``` repository to the home directory of the user, who runs the remote Jupyter notebook. Alternatively, you can simply configure ```root``` yourself.\n",
    "4. We import the modules contained in ```lib/``` to hide most of the boilerplate code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearnex import patch_sklearn \n",
    "\n",
    "patch_sklearn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import expanduser, join\n",
    "import pathlib\n",
    "\n",
    "root = pathlib.Path().resolve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "\n",
    "dir = listdir(root)\n",
    "if 't.ex-Graph' in dir:\n",
    "  root = join(root, 't.ex-Graph')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, join(root, 'lib'))\n",
    "\n",
    "import config\n",
    "import data\n",
    "import model\n",
    "import export"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Sets\n",
    "\n",
    "We use the two variants of t.ex-Graph: the one, in which nodes represent fully qualified domain names (FQDN), and the one, in which nodes represent a second-level domain (SLD). Therefore, we read in the two files ```graph-data-fqdn.csv``` and ```graph-data-sld.csv```, respectively. We derive a label ```binary_tracker``` from the column ```tracking```, which represents the ratio between incoming tracking requests and the total number of incoming requests. We label a node as ```tracker``` (or ```1```), if this ratio is greater than 0, and as ```non-tracker``` (or ```0```), if the ratio is 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = [\n",
    "\n",
    "  {\n",
    "    'label': 't.ex-Graph (FQDN)',\n",
    "    'data': data.read(join(root, 'data', 'graph-data-fqdn.csv')),\n",
    "    'smote': True\n",
    "  },\n",
    "\n",
    "  {\n",
    "    'label': 't.ex-Graph (SLD)',\n",
    "    'data': data.read(join(root, 'data', 'graph-data-sld.csv')),\n",
    "    'smote': True\n",
    "  },\n",
    "\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in datasets:\n",
    "  data.binary_classification_labels(\n",
    "    config.binary_tracker, \n",
    "    dataset.get('data'),\n",
    "    lambda x : x > 0.5\n",
    "  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inbalanced Tracker Distribution\n",
    "\n",
    "We investigate the distribution of ```tracker``` and ```non-tracker```. As we can see in the figure below, the majority of nodes is labeled as ```non-tracker```, i.e. that these nodes do not retrieve a single tracking request. The distribution varies between the two variants of t.ex-Graph. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from export import mkdir_p\n",
    "from os.path import join\n",
    "\n",
    "fig, axes = plt.subplots(ncols=len(datasets), figsize=(8, 4))\n",
    "\n",
    "for index, dataset in enumerate(datasets):\n",
    "  x = dataset['data'][config.binary_tracker]\n",
    "  percentage = lambda i: len(i) / float(len(x)) * 100\n",
    "  sns.barplot(\n",
    "    x=x, y=x, ax=axes[index], estimator=percentage\n",
    "  ).set(\n",
    "    title=dataset['label'], \n",
    "    xlabel=config.binary_tracker,\n",
    "    ylabel='Percentage'\n",
    "  )\n",
    "\n",
    "dir = join(root, config.results_dir)\n",
    "mkdir_p(dir)\n",
    "plt.savefig(join(dir, 'inbalanced-tracker-distribution.pdf'), dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "fig, axes = plt.subplots(ncols=len(datasets), figsize=(18, 7))\n",
    "\n",
    "for index, dataset in enumerate(datasets):\n",
    "  corr = dataset['data'].corr(numeric_only=True)\n",
    "  \n",
    "  ax = sns.heatmap(corr, cmap='Blues', ax=axes[index])\n",
    "  ax.set(\n",
    "    title=dataset['label'],\n",
    "    xticks=[]\n",
    "  )\n",
    "\n",
    "  if index == 1:\n",
    "    ax.set(yticks=[])\n",
    "\n",
    "dir = join(root, config.results_dir)\n",
    "mkdir_p(dir)\n",
    "plt.subplots_adjust(right=1)\n",
    "plt.savefig(join(dir, 'dataset-correlations.pdf'), dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = data.feature_vector(datasets[0].get('data'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "sns.pairplot(\n",
    "  datasets[0]['data'], \n",
    "  hue=config.binary_tracker, \n",
    "  vars=features,\n",
    "  diag_kind=\"hist\",\n",
    "  diag_kws=dict(\n",
    "    color=\".2\", \n",
    "    hue=datasets[0]['data'][config.binary_tracker]\n",
    "  ),\n",
    "  corner=True\n",
    ")\n",
    "\n",
    "dir = join(root, config.results_dir)\n",
    "mkdir_p(dir)\n",
    "plt.savefig(join(dir, 'pairplot.pdf'), dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = [ \n",
    "  config.binary_tracker\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = dict()\n",
    "for target in targets:\n",
    "  models[target] = list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "models[config.binary_tracker] = [\n",
    "    LogisticRegression(max_iter=10000, solver='liblinear', n_jobs=-1),\n",
    "    KNeighborsClassifier(weights='distance', n_jobs=-1),\n",
    "    SVC(),\n",
    "    DecisionTreeClassifier(),\n",
    "    RandomForestClassifier(n_jobs=-1),\n",
    "    AdaBoostClassifier(),\n",
    "    GradientBoostingClassifier(),\n",
    "    XGBClassifier(learning_rate=0.2, subsample=0.5),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_options = {\n",
    "  'classifications': True,\n",
    "  'feature_importances': False,\n",
    "  'cross_validations': False,\n",
    "  'misclassifications': True\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib agg\n",
    "\n",
    "results = model.compute_results(\n",
    "  datasets, \n",
    "  models, \n",
    "  features, \n",
    "  targets,\n",
    "  root,\n",
    "  compute_options\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"%matplotlib inline\"\"\"\n",
    "\n",
    "if compute_options['classifications'] is True:\n",
    "  export.classification_results(results, root)\n",
    "\n",
    "if compute_options['feature_importances'] is True:\n",
    "  export.feature_importances(results, root)\n",
    "\n",
    "if compute_options['cross_validations'] is True:\n",
    "  export.cross_validation(results, root)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
